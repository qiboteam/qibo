{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double-bracket Iteration Scheduling Strategies\n",
    "\n",
    "This notebook presents the different strategies for scheduling the step durations for the double-bracket iteration algorithm and their resepctive accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qibo import hamiltonians, set_backend\n",
    "from qibo.models.dbi.double_bracket import DoubleBracketGeneratorType, DoubleBracketScheduling, DoubleBracketIteration\n",
    "from qibo.models.dbi.utils import *\n",
    "from qibo.models.dbi.utils_scheduling import *\n",
    "from qibo.models.dbi.utils_strategies import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical\n",
    "Set up the basic test case with the transverse field ising model hamiltonian and the canonical bracket as the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian\n",
    "set_backend(\"qibojit\", platform=\"numba\")\n",
    "\n",
    "# hamiltonian parameters\n",
    "nqubits = 5\n",
    "h = 3\n",
    "\n",
    "# define the hamiltonian\n",
    "H_TFIM = hamiltonians.TFIM(nqubits=nqubits, h=h)\n",
    "\n",
    "# initialize class\n",
    "dbi = DoubleBracketIteration(deepcopy(H_TFIM),mode=DoubleBracketGeneratorType.canonical)\n",
    "print(\"Initial off diagonal norm\", dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run a sweep of step duration to map the off-diagonal norm in this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for plotting sigma decrease of the first step\n",
    "s_space = np.linspace(1e-5, 0.6, 100)\n",
    "off_diagonal_norm_diff = []\n",
    "for s in s_space:\n",
    "    dbi_eval = deepcopy(dbi)\n",
    "    dbi_eval(s)\n",
    "    off_diagonal_norm_diff.append(dbi_eval.off_diagonal_norm - dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default scheduling strategy is grid search: `DoubleBracketScheduling.\n",
    "grid_serach`. This strategy specifies a list of step durations to test one by one and finds the one that maximizes the cost function (off-digonal norm of Hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.grid_search)\n",
    "print('grid_search step:', step_grid)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.hyperopt, max_evals=100, step_max=0.6)\n",
    "print('hyperopt_search step:', step_hyperopt)\n",
    "step_poly = dbi.choose_step(scheduling=DoubleBracketScheduling.polynomial_approximation, n=5)\n",
    "print('polynomial_approximation step:', step_poly)\n",
    "step_sa = dbi.choose_step(scheduling=DoubleBracketScheduling.simulated_annealing)\n",
    "print('simulated_annealing step:', step_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.axvline(x=step_sa, color='b', linestyle=':',label='simulated annealing')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title('First DBI step')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specified diagonal operator\n",
    "\n",
    "While for the cannonical case, all the scheduling methods are accurate, it is important to realize that the global minimum of the loss function is not always so obvious. It is thus necessary to show whether the 3 converges to an agreeable step duration using different iteration generators, such as the Pauli 'ZZ..Z' operator and 'ZZ..I' operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the digaonal operators\n",
    "Z_str = \"Z\"*nqubits\n",
    "ZI_str = \"Z\"*(nqubits-1)+\"I\"\n",
    "Z_op = SymbolicHamiltonian(str_to_symbolic(Z_str)).dense.matrix\n",
    "ZI_op = SymbolicHamiltonian(str_to_symbolic(ZI_str)).dense.matrix\n",
    "op_dict = {Z_str:Z_op, ZI_str: ZI_op}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi = DoubleBracketIteration(deepcopy(H_TFIM),mode=DoubleBracketGeneratorType.single_commutator)\n",
    "d_str = ZI_str\n",
    "d = op_dict[d_str]\n",
    "# generate data for plotting sigma decrease of the first step\n",
    "s_space = np.linspace(1e-5, 0.6, 100)\n",
    "off_diagonal_norm_diff = []\n",
    "for s in s_space:\n",
    "    dbi_eval = deepcopy(dbi)\n",
    "    dbi_eval(s,d=d)\n",
    "    off_diagonal_norm_diff.append(dbi_eval.off_diagonal_norm - dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.grid_search, step_max=0.6, d=d)\n",
    "grid_min = dbi.loss(step=step_grid, d=d)-dbi.off_diagonal_norm\n",
    "print('grid_search step:', step_grid, 'loss', grid_min)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.hyperopt, d=d, max_evals=100, step_max=0.6)\n",
    "hyperopt_min = dbi.loss(step=step_hyperopt, d=d)-dbi.off_diagonal_norm\n",
    "print('hyperopt_search step:', step_hyperopt, 'loss', hyperopt_min)\n",
    "# polynomial expansion\n",
    "step_poly = dbi.choose_step(scheduling=DoubleBracketScheduling.polynomial_approximation, d=d, n=5)\n",
    "poly_min = dbi.loss(step=step_poly, d=d)-dbi.off_diagonal_norm\n",
    "print('polynomial_approximation step:', step_poly, 'loss', poly_min)\n",
    "# simulated annealing\n",
    "step_sa = dbi.choose_step(scheduling=DoubleBracketScheduling.simulated_annealing, d=d)\n",
    "sa_min = dbi.loss(step=step_sa, d=d)-dbi.off_diagonal_norm\n",
    "print('simulated_annealing step:', step_sa, 'loss', sa_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.text(x=step_grid, y=grid_min, s=f'grid min \\n{round(grid_min,3)}')\n",
    "plt.text(x=step_poly, y=poly_min, s=f'poly min \\n{round(poly_min,3)}')\n",
    "plt.text(x=step_sa, y=sa_min, s=f'sa min \\n{round(sa_min,3)}')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.axvline(x=step_sa, color='b', linestyle=':',label='simulated annealing')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title(f'First DBI step with D={d_str}')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are two similar \"minimal point\" at 0.03 and 0.22, with the latter being the absolute minimum by an insignificant advantage. However, for practical reasons, we prefer taking the first close-minimum calculated by polynomial approximation. Hence, we can use the polynomial approximation to restrict the search area and obtain better results. For example, we define a search range of 0.1 around the polynomial step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use polynomial expansion as an restriction for hyperopt/grid range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_range = 0.1\n",
    "if step_poly < search_range/2:\n",
    "    step_min = 0\n",
    "    step_max = search_range\n",
    "else:\n",
    "    step_min = step_poly - search_range/2\n",
    "    step_max = step_poly + search_range/2\n",
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.grid_search, step_min=step_min, step_max=step_max, d=d)\n",
    "print('grid_search step:', step_grid)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.hyperopt, step_min=step_min, step_max=step_max, max_evals=100, d=d,)\n",
    "print('hyperopt_search step:', step_hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title(r'Restrict $s$ with polynomial')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we see that the strategy is indeed effective for finding the first minimum of the loss funciton for both the Z operator and the ZI operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare in Pauli-Z strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qibo.quantum_info import random_hermitian\n",
    "from qibo.hamiltonians import Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian\n",
    "set_backend(\"qibojit\", platform=\"numba\")\n",
    "nqubits = 4\n",
    "h0 = random_hermitian(2**nqubits)\n",
    "\n",
    "# initialize class\n",
    "dbi = DoubleBracketIteration(deepcopy(Hamiltonian(nqubits=nqubits, matrix=h0)),mode=DoubleBracketGeneratorType.single_commutator)\n",
    "print(\"Initial off diagonal norm\", dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_local_Z = generate_Z_operators(nqubits)\n",
    "Z_ops = list(generate_local_Z.values())\n",
    "Z_names = list(generate_local_Z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSTEPS = 8\n",
    "scheduling_list = [DoubleBracketScheduling.grid_search,\n",
    "                   DoubleBracketScheduling.hyperopt,\n",
    "                   DoubleBracketScheduling.polynomial_approximation,\n",
    "                   DoubleBracketScheduling.simulated_annealing,]\n",
    "scheduling_labels = ['grid search',\n",
    "                     'hyperopt',\n",
    "                     'polynomial',\n",
    "                     'simulated_annealing']\n",
    "Z_optimal_scheduling = []\n",
    "s_scheduling = []\n",
    "off_norm_scheduling =[]\n",
    "for i,scheduling in enumerate(scheduling_list):\n",
    "    # reinitialize\n",
    "    dbi = DoubleBracketIteration(Hamiltonian(nqubits=nqubits, matrix=deepcopy(h0)), mode=DoubleBracketGeneratorType.single_commutator)\n",
    "    Z_optimal = []\n",
    "    # add in initial values for plotting\n",
    "    off_diagonal_norm_history = [dbi.off_diagonal_norm]\n",
    "    steps = [0]\n",
    "    print(f'----------Scheduling {scheduling_labels[i]}----------')\n",
    "    for _ in range(NSTEPS):\n",
    "        dbi, idx, step, flip_sign = select_best_dbr_generator(dbi, Z_ops, scheduling=scheduling, compare_canonical=False)\n",
    "        off_diagonal_norm_history.append(dbi.off_diagonal_norm)\n",
    "        steps.append(steps[-1]+step)\n",
    "        if flip_sign < 0:\n",
    "            Z_optimal.append('-' + Z_names[idx])\n",
    "        else:\n",
    "            Z_optimal.append(Z_names[idx])\n",
    "        print(f\"New optimized step at iteration {_+1}/{NSTEPS}: {step} with operator {Z_optimal[-1]}, loss {dbi.off_diagonal_norm}\")\n",
    "    Z_optimal_scheduling.append(Z_optimal)\n",
    "    s_scheduling.append(steps)\n",
    "    off_norm_scheduling.append(off_diagonal_norm_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, scheduling in enumerate(scheduling_labels):\n",
    "    plt.plot(s_scheduling[i], off_norm_scheduling[i], '-o', label=scheduling)\n",
    "plt.xlabel(\"Step durations\")\n",
    "plt.ylabel(\"Norm off-diagonal restriction\")\n",
    "plt.title(\"Compare Variational Pauli-Z using different scheduling strategies\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When polynomial approximation has no solution\n",
    "\n",
    "In some cases, the prescribed taylor expansion order `n` may not be sufficient to produce a meaningful step duration (real positive). In these cases, we rely on a backup scheduling method in `choose_step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian\n",
    "set_backend(\"qibojit\", platform=\"numba\")\n",
    "\n",
    "# hamiltonian parameters\n",
    "nqubits = 5\n",
    "h = 3\n",
    "\n",
    "# define the hamiltonian\n",
    "H_TFIM = hamiltonians.TFIM(nqubits=nqubits, h=h)\n",
    "\n",
    "# initialize class\n",
    "dbi = DoubleBracketIteration(deepcopy(H_TFIM),mode=DoubleBracketGeneratorType.canonical)\n",
    "dbi.scheduling = DoubleBracketScheduling.polynomial_approximation\n",
    "print(\"Initial off diagonal norm\", dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we let `n=1` which is a linear fit to the loss function. This results in no valid solutions and function `polynomial_step` returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range (5):\n",
    "    step = polynomial_step(dbi, n=n)\n",
    "    print(n, step)\n",
    "print(dbi.choose_step(n=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "48caf7dabad7b721a854729228548373f17e53f40870080394d552284aea7c35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
