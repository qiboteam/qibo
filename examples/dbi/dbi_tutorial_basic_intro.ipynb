{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb748c1a-2ecd-44a2-91d8-c1255a00615b",
   "metadata": {},
   "source": [
    "## Double-Bracket Iteration diagonalization algorithm\n",
    "\n",
    "In this example we present the `Qibo`'s implementation of the Double-Bracket Iteration (DBI) algorithm, which can be used to prepare the eigenstates of a quantum system. \n",
    "\n",
    "#### The initial setup\n",
    "\n",
    "At first we import some useful packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f362b8-eb73-456e-ae48-94c5f2a12649",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install seaborn # plotting library\n",
    "!python -m pip install hyperopt # required to optimize the DBF step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270b1ea-ee6a-4eac-a0ff-3d7dae296cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "\n",
    "from qibo import hamiltonians, set_backend\n",
    "from qibo.models.dbi.double_bracket import DoubleBracketGeneratorType, DoubleBracketIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e5402-ea34-4979-bb79-fd395567f77d",
   "metadata": {},
   "source": [
    "Here we define a simple plotting function useful to keep track of the diagonalization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec7b46-19b9-4004-93c0-a90255e58fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matrix(matrix, title=\"\"):\n",
    "    \"\"\"Visualize hamiltonian in a heatmap form.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_title(title)\n",
    "    try:\n",
    "        im = ax.imshow(np.absolute(matrix), cmap=\"inferno\")\n",
    "    except TypeError:\n",
    "        im = ax.imshow(np.absolute(matrix.get()), cmap=\"inferno\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "def visualize_drift(h0, h):\n",
    "    \"\"\"Visualize drift of the evolved hamiltonian w.r.t. h0.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_title(r\"Drift: $|\\hat{H}_0 - \\hat{H}_{\\ell}|$\")\n",
    "    try:\n",
    "        im = ax.imshow(np.absolute(h0 - h), cmap=\"inferno\")\n",
    "    except TypeError:\n",
    "        im = ax.imshow(np.absolute((h0 - h).get()), cmap=\"inferno\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "def plot_histories(histories, labels):\n",
    "    \"\"\"Plot off-diagonal norm histories over a sequential evolution.\"\"\"\n",
    "    colors = sns.color_palette(\"inferno\", n_colors=len(histories)).as_hex()\n",
    "    plt.figure(figsize=(5,5*6/8))\n",
    "    for i, (h, l) in enumerate(zip(histories, labels)):\n",
    "        plt.plot(h, lw=2, color=colors[i], label=l, marker='.')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(r\"$\\| \\sigma(\\hat{H}) \\|^2$\")\n",
    "    plt.title(\"Loss function histories\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cd7cc-9952-4da4-baef-e916300a9365",
   "metadata": {},
   "source": [
    "We need to define a target hamiltonian which we aim to diagonalize. As an example, we consider the Transverse Field Ising Model (TFIM):\n",
    "$$ H_{\\rm TFIM} = - \\sum_{q=0}^{N}\\bigl( Z_i Z_{i+1} + h X_i \\bigr),$$\n",
    "which is already implemented in `Qibo`. For this tutorial we set $N=6$ and $h=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ed408-68ed-4054-825c-2a7df0979a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the qibo backend (we suggest qibojit if N >= 20)\n",
    "set_backend(\"qibojit\", \"numba\")\n",
    "\n",
    "# hamiltonian parameters\n",
    "nqubits = 5\n",
    "h = 3\n",
    "\n",
    "# define the hamiltonian\n",
    "h = hamiltonians.TFIM(nqubits=nqubits, h=h)\n",
    "\n",
    "# vosualize the matrix\n",
    "visualize_matrix(h.matrix, title=\"Target hamiltonian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794e779-bf2d-4ab5-97ce-f876d9522a35",
   "metadata": {},
   "source": [
    "#### The generator of the evolution\n",
    "\n",
    "The model is implemented following the procedure presented in [1], and the first practical step is to define the generator of the iteration $\\hat{\\mathcal{U}}_{\\ell}$, which executes one diagonalization step $$\\hat{H}_{\\ell} = \\hat{\\mathcal{U}}_{\\ell}^{\\dagger} \\hat{H} \\hat{\\mathcal{U}}_{\\ell}.$$\n",
    "In `Qibo`, we define the iteration type through a `DoubleBracketGeneratorType` object, which can be chosen between one of the following:\n",
    "- `canonical`: the generator of the iteration at step $k+1$ is defined using the commutator between the off diagonal part $\\sigma(\\hat{H_k})$ and the diagonal part $\\Delta(\\hat{H}_k)$ of the target evolved hamiltonian:\n",
    "  $$\\hat{\\mathcal{U}}_{k+1}=\\exp\\bigl\\{s[\\Delta(\\hat{H}_k), \\sigma(\\hat{H}_k)]\\bigr\\}.$$ \n",
    "- `single_commutator`: the evolution follows a similar procedure of the previous point in this list, but any additional matrix $D_k$ can be used to control the evolution at each step:\n",
    "    $$ \\hat{\\mathcal{U}}_{k+1}=\\exp\\bigl\\{s[D_k, \\hat{H}_k]\\bigr\\}. $$\n",
    "- `group_commutator`: the following group commutator is used to compute the evolution:\n",
    "  $$  \\hat{\\mathcal{U}}_{k+1}= e^{is\\hat{H_k}} e^{isD_k} e^{-is\\hat{H_k}} e^{-isD_k}, $$\n",
    "which approximates the canonical commutator for small $s$.\n",
    "\n",
    "In order to set one of this evolution generators one can do as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a487e9-366b-4203-b660-e3d4af2bcb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a look inside the DoubleBracketGeneratorType class\n",
    "for generator in DoubleBracketGeneratorType:\n",
    "    print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8dce89-27f6-403d-982a-58d531fade48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the canonical generator\n",
    "iterationtype = DoubleBracketGeneratorType.canonical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f9f75-0548-4533-a13c-3aba3191e608",
   "metadata": {},
   "source": [
    "#### The `DoubleBracketIteration` class\n",
    "\n",
    "A `DoubleBracketIteration` object can be initialize by calling the `qibo.models.double_braket.DoubleBracketIteration` model and passing the target hamiltonian and the generator type we want to use to perform the evolutionary steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055870ec-55f2-4b99-a622-e3aa4c7dd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf = DoubleBracketIteration(hamiltonian=deepcopy(h), mode=iterationtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cf803-60b4-467a-be8e-cbad5d81f14a",
   "metadata": {},
   "source": [
    "#### `DoubleBracketIteration` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e278c3d-9f34-4a40-b453-4e030c751ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on which qibo backend am I running the algorithm?\n",
    "print(f\"Backend: {dbf.backend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e142b-a0a2-41bd-a16a-265a420b7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the initial target hamiltonian is a qibo hamiltonian\n",
    "# thus the matrix can be accessed typing h.matrix\n",
    "print(f\"Initial form of the target hamiltonian:\\n{dbf.h0.matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d1d41-3df7-49cf-96ca-fa1019c00c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize it in a more graphical way\n",
    "visualize_matrix(dbf.h0.matrix, r\"$H_0$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b864712-219c-44b6-8337-19ef0100e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we didn't perform yet any evolutionary step they are the same\n",
    "visualize_drift(dbf.h0.matrix, dbf.h.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e576bc4-4e79-4c71-9ea0-b3012e9f2ba1",
   "metadata": {},
   "source": [
    "which shows $\\hat{H}$ is now identical to $\\hat{H}_0$ since no evolution step has been performed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d3aaa-17e1-492e-bcd3-b510f44a5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagonal part of the H target\n",
    "visualize_matrix(dbf.diagonal_h_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ce252",
   "metadata": {},
   "source": [
    "The Hilbert-Schmidt norm of a Hamiltonian is defined as:\n",
    "\n",
    "$\\lang A\\rang_{HS}=\\sqrt{A^\\dagger A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0dfa1-7039-4d7d-8aa3-5a937b9ab0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilbert-Schmidt norm of the off-diagonal part\n",
    "# which we want to bring to be close to zero\n",
    "print(f\"HS norm of the off diagonal part of H: {dbf.off_diagonal_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e35ab-66f4-49f9-af19-679c20065a11",
   "metadata": {},
   "source": [
    "Finally, the energy fluctuation of the system at step $k$ over a given state $\\mu$\n",
    "\n",
    "$$ \\Xi(\\mu) = \\sqrt{\\langle \\mu | \\hat{H}_k^2 | \\mu \\rangle - \\langle \\mu | \\hat{H}_k | \\mu \\rangle^2} $$\n",
    "\n",
    "can be computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8d86f-07d4-498c-acb1-f6f6a4614c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a quantum state\n",
    "# for example the ground state of a multi-qubit Z hamiltonian\n",
    "Z = hamiltonians.Z(nqubits=nqubits)\n",
    "state = Z.ground_state()\n",
    "\n",
    "# compute energy fluctuations using current H and given state\n",
    "dbf.energy_fluctuation(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b37f3-2477-49a0-9f80-7da5ddda1fff",
   "metadata": {},
   "source": [
    "#### Call the `DoubleBracketIteration` to perform a DBF iteration\n",
    "\n",
    "If the DBF object is called, a Double Bracket Iteration iteration is performed. This can be done customizing the iteration by setting the iteration step and the desired `DoubleBracketGeneratorType`. If no generator is provided, the one passed at the initialization time is used (default is `DoubleBracketGeneratorType.canonical`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a886261-8aa6-4df0-a31b-9c39847db124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one evolution step\n",
    "\n",
    "# initial value of the off-diagonal norm\n",
    "print(f\"Initial value of the off-diagonal norm: {dbf.off_diagonal_norm}\")\n",
    "\n",
    "dbf(step=0.01, mode=iterationtype)\n",
    "\n",
    "# after one step\n",
    "print(f\"One step later off-diagonal norm: {dbf.off_diagonal_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78dd05d-ffe3-435a-b5ec-2a42f28066b2",
   "metadata": {},
   "source": [
    "We can check now if something happened by plotting the drift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74812d-7c2c-44e4-afc2-e235968801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_drift(dbf.h0.matrix, dbf.h.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465a422-eebf-4e80-ae96-bba894132330",
   "metadata": {},
   "source": [
    "The set step can be good, but maybe not the best one. In order to do this choice in a wiser way, we can call the DBF hyperoptimization routine to search for a better initial step. The `dbf.hyperopt_step` method is built on top of the [`hyperopt`](https://hyperopt.github.io/hyperopt/) package. Any algorithm or sampling space provided by the official package can be used. We are going to use the default options (we sample new steps from a uniform space following a _Tree of Parzen estimators algorithm_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad79966-7a11-4a45-aba5-4a4bb8315c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart\n",
    "dbf.h = dbf.h0\n",
    "\n",
    "# optimization of the step, we allow to search in [1e-5, 1]\n",
    "step = dbf.hyperopt_step(\n",
    "    step_min = 1e-5,\n",
    "    step_max = 1,\n",
    "    space = hp.uniform,\n",
    "    optimizer = tpe,\n",
    "    max_evals = 1000,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49483a47-d29d-440e-a4bc-143bfe6bb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbf.h.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdaf7f9-7e49-4a16-8b29-ae1f9746cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_drift(dbf.h0.matrix, dbf.h.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f1d00e-e763-40d9-822f-e0e8d4c57d9a",
   "metadata": {},
   "source": [
    "#### Let's evolve the model for `NSTEPS`\n",
    "\n",
    "We know recover the initial hamiltonian, and we perform a sequence of DBF iteration steps, in order to show how this mechanism can lead to a proper diagonalization of the target hamiltonian.\n",
    "\n",
    "#### Method 1: fixed step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6a485-a714-4e14-b27a-1df2930068ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart\n",
    "dbf_1 = DoubleBracketIteration(hamiltonian=deepcopy(h), mode=iterationtype)\n",
    "off_diagonal_norm_history = [dbf_1.off_diagonal_norm]\n",
    "histories, labels = [], [\"Fixed step\"]\n",
    "\n",
    "# set the number of evolution steps\n",
    "NSTEPS = 20\n",
    "step = 0.005\n",
    "\n",
    "for s in range(NSTEPS):\n",
    "    dbf_1(step=step)\n",
    "    off_diagonal_norm_history.append(dbf_1.off_diagonal_norm)\n",
    "\n",
    "histories.append(off_diagonal_norm_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b2f18-ca53-4f34-9fcf-0052dcc31dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histories(histories, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb797d6c-0eba-4da4-b492-8b5d70f9123f",
   "metadata": {},
   "source": [
    "#### Method 2: optimizing the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd1e33-3620-4f3b-b705-a120f6da0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart\n",
    "dbf_2 = DoubleBracketIteration(hamiltonian=deepcopy(h), mode=iterationtype)\n",
    "off_diagonal_norm_history = [dbf_2.off_diagonal_norm]\n",
    "\n",
    "# set the number of evolution steps\n",
    "NSTEPS = 20\n",
    "\n",
    "# optimize first step\n",
    "step = dbf_2.hyperopt_step(\n",
    "    step_min = 1e-5,\n",
    "    step_max = 1,\n",
    "    space = hp.uniform,\n",
    "    optimizer = tpe,\n",
    "    max_evals = 500,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "for s in range(NSTEPS):\n",
    "    if s != 0:\n",
    "        step = dbf_2.hyperopt_step(\n",
    "            step_min = 1e-5,\n",
    "            step_max = 1,\n",
    "            space = hp.uniform,\n",
    "            optimizer = tpe,\n",
    "            max_evals = 100,\n",
    "        )\n",
    "        print(f\"New optimized step at iteration {s}/{NSTEPS}: {step}\")\n",
    "    dbf_2(step=step)\n",
    "    off_diagonal_norm_history.append(dbf_2.off_diagonal_norm)\n",
    "\n",
    "histories.append(off_diagonal_norm_history)\n",
    "labels.append(\"Optimizing step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0212bf-b642-4fea-9203-037876e0b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histories(histories, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32341937-4178-41d2-a10e-5e4d2634098e",
   "metadata": {},
   "source": [
    "The hyperoptimization can lead to a faster convergence of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b89092-07e5-4788-9ae0-8907df2428eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbf_1.h.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ed320-04a8-42af-a980-48ab4f1fff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbf_2.h.matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
